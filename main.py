import telebot
import os
import chromadb
from chromadb.config import Settings
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
from sentence_transformers import SentenceTransformer
from llama_index.llms.ollama import Ollama
from llama_index.core.llms import ChatMessage
from duckduckgo_search import DDGS
import requests
from llama_index.embeddings.huggingface import HuggingFaceEmbedding  
from bs4 import BeautifulSoup
import time

# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å SentenceTransformer
model_name = "all-MiniLM-L6-v2"
try:
    embedding_model = SentenceTransformer(model_name)
    print("–ú–æ–¥–µ–ª—å SentenceTransformer –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ —Å –≤–∞—à–∏–º —Ç–æ–∫–µ–Ω–æ–º
bot = telebot.TeleBot('7563626842:AAH02HKNgRO1WwUqCZnYNWC-K7kj80uO9Kw')

# ChromaDB
chroma_storage_path = os.path.join(os.getcwd(), "chroma_db")
chroma_settings = Settings(persist_directory=chroma_storage_path)
client = chromadb.PersistentClient(path=chroma_storage_path)

embedding_func = HuggingFaceEmbedding(model_name=model_name)  

# Collection in ChromaDB
collection_name = "chat_data"
collection = client.get_or_create_collection(
    name=collection_name,
    embedding_function=SentenceTransformerEmbeddingFunction(model_name=model_name)
)

# –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–∏—Å–∫ DuckDuckGo —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
def duckduckgo_search_safe(query, max_results=3, retries=3):
    results = []
    for attempt in range(retries):
        try:
            with DDGS() as ddgs:
                for r in ddgs.text(query, max_results=max_results):
                    if r.get("href"):
                        results.append(r["href"])
            return results
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ DuckDuckGo (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}): {str(e)}")
            time.sleep(5)
    return []

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
def fetch_page_content(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        resp = requests.get(url, headers=headers, timeout=10)
        resp.raise_for_status()
        soup = BeautifulSoup(resp.text, "html.parser")
        paragraphs = soup.find_all("p")
        page_text = " ".join([p.get_text() for p in paragraphs])
        return page_text.strip()
    except Exception:
        return ""

# –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
def truncate_text(text, max_words=500):
    words = text.split()
    if len(words) <= max_words:
        return text
    truncated_text = " ".join(words[:max_words])
    last_period_index = truncated_text.rfind(".")
    if last_period_index != -1:
        truncated_text = truncated_text[:last_period_index + 1]
    return truncated_text

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@bot.message_handler(commands=['start'])
def send_welcome(message):
    bot.reply_to(message, "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Ollama –∏ DuckDuckGo. –ó–∞–¥–∞–π—Ç–µ –º–Ω–µ –≤–æ–ø—Ä–æ—Å, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å!")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@bot.message_handler(func=lambda message: True)
def handle_message(message):
    user_input = message.text

    # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ DuckDuckGo
    urls = duckduckgo_search_safe(user_input, max_results=3)
    bot.send_message(message.chat.id, f"üîé –ù–∞–π–¥–µ–Ω–æ {len(urls)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –∏–∑–≤–ª–µ–∫–∞—é —Ç–µ–∫—Å—Ç...")

    context = ""
    for url in urls:
        page_text = fetch_page_content(url)
        truncated_text = truncate_text(page_text, max_words=500)
        if len(truncated_text.strip()) > 30:
            context += f"\nüîó –ò—Å—Ç–æ—á–Ω–∏–∫: {url}\n{truncated_text}\n"

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è Ollama
    messages = [ChatMessage(role="user", content=context)] if context else []
    messages.append(ChatMessage(role="user", content=user_input))

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama
    llm = Ollama(model="llama3.2", request_timeout=120.0)
    bot.send_message(message.chat.id, "ü§ñ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

    try:
        response_stream = llm.stream_chat(messages=messages)
        response = ""
        for chunk in response_stream:
            response += chunk.delta
        bot.reply_to(message, response)
    except Exception as e:
        bot.reply_to(message, f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
bot.polling(none_stop=True)
